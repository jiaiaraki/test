{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20201125_myOwnCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMy95tRwB5Wnll3YYhLtNA3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiaiaraki/test/blob/main/20201125_myOwnCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKSv20ykHtTq"
      },
      "source": [
        "### numpyだけでCNN実装\n",
        "https://qiita.com/ta-ka/items/1c588dd0559d1aad9921\n",
        "\n",
        "**<font color = red size = 8>！overflow！</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSmt6VpmH337"
      },
      "source": [
        "#### CNN\n",
        "- 畳込み層\n",
        "- プーリング層\n",
        "\n",
        "#### 学習\n",
        "- 重みの更新\n",
        "- 誤差逆伝播\n",
        "\n",
        "#### pythonでの実装\n",
        "- 畳込み層の実装\n",
        "- プーリング層の実装\n",
        "\n",
        "#### MNISTデータセットでの実験\n",
        "- 学習\n",
        "- 結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOg9txjZHs1o"
      },
      "source": [
        "## activator.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Activator:\n",
        "  class linear(object):\n",
        "    def __init__(self):\n",
        "      'linear class'\n",
        "\n",
        "    def activate(self, x):\n",
        "      return x\n",
        "\n",
        "    def derivate(self, x):\n",
        "      return np.ones_like(x)\n",
        "\n",
        "\n",
        "  class sigmoid(object):\n",
        "    def __init__(self):\n",
        "      'sigmoid class'\n",
        "\n",
        "    def activate(self, x):\n",
        "      return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "    def derivate(self, x):\n",
        "      return x * (1.0 - x)\n",
        "\n",
        "\n",
        "  class softmax(object):\n",
        "    def __init__(self):\n",
        "      'softmax class'\n",
        "      \n",
        "    def activate(self, x):\n",
        "      exp = np.exp(x)\n",
        "      return exp / exp.sum(axis = 0)\n",
        "\n",
        "    def derivate(self, x):\n",
        "      return x * (1.0 - x)\n",
        "\n",
        "\n",
        "  class relu(object):\n",
        "    def __init__(self):\n",
        "      'relu class'\n",
        "\n",
        "    def activate(self, x):\n",
        "      return np.maximum(x, 0.0)\n",
        "\n",
        "    def derivate(self, x):\n",
        "      return np.vectorize(lambda _x: 0.0 if _x < 0.0 else 1.0)(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsuxXsQdHs3b"
      },
      "source": [
        "## cnn.py\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "\n",
        "class CNN(object):\n",
        "  def __init__(self, conv1, pool1, conv2, pool2, neural, error):\n",
        "    self.conv1 = conv1\n",
        "    self.pool1 = pool1\n",
        "    self.conv2 = conv2\n",
        "    self.pool2 = pool2\n",
        "    self.neural = neural\n",
        "    self.error = error\n",
        "\n",
        "  def train(self, X, T, epsilon, lam, gamma, s_batch, epochs):\n",
        "    n_data = X.shape[0]\n",
        "    self.__set_loss(epochs)\n",
        "    for epo in range(epochs):\n",
        "      perm = np.random.permutation(n_data)\n",
        "      for i in range(0, n_data, s_batch):\n",
        "        x, t = X[perm[i:i+s_batch]], T[perm[i:i+s_batch]].T\n",
        "\n",
        "        # forward\n",
        "        cv1, pl1, cv2, pl2, u, z, y = self.__forward(x, s_batch)\n",
        "\n",
        "        # backward\n",
        "        output_delta, hidden_delta, input_delta = self.neural.backward(t, y, z, u, self.error)\n",
        "        pl2_delta, cv2_delta, pl1_delta, cv1_delta = self.__backward(input_delta, pl2, cv2, pl1, cv1)\n",
        "\n",
        "        # update weight\n",
        "        self.neural.update_weight(output_delta, hidden_delta, z, u, epsilon, lam)\n",
        "        self.conv2.update_weight(cv2_delta, epsilon)\n",
        "        self.conv1.update_weight(cv1_delta, epsilon)\n",
        "\n",
        "        # accumulate loss\n",
        "        self.__accumulate_loss(y, t, n_data, epo)\n",
        "\n",
        "      # update learning rate\n",
        "      if (epo + 1) % 10 == 0: epsilon = self.__update_epsilon(epsilon, gamma)\n",
        "      print('epoch: {0}, loss: {1}'.format(epo, self.__loss[epo]))\n",
        "\n",
        "  def predict(self, X):\n",
        "    return self.__forward(X, X.shape[0])[6]\n",
        "\n",
        "  def accuracy(self, Y, T):\n",
        "    return (Y.argmax(axis = 0) == T.argmax(axis = 1)).sum() * 1.0 / Y.shape[1]\n",
        "\n",
        "  def save_lossfig(self, fn = 'loss.png'):\n",
        "    pyplot.plot(np.arange(self.__loss.size), self.__loss)\n",
        "    pyplot.savefig(fn)\n",
        "\n",
        "  def __forward(self, X, s_batch):\n",
        "    cv1 = self.conv1.forward(X)\n",
        "    pl1 = self.pool1.forward(cv1)\n",
        "    cv2 = self.conv2.forward(pl1)\n",
        "    pl2 = self.pool2.forward(cv2)\n",
        "    u = pl2.reshape(s_batch, -1).T\n",
        "    z, y = self.neural.forward(u)\n",
        "    return cv1, pl1, cv2, pl2, u, z, y\n",
        "\n",
        "  def __backward(self, input_delta, pl2, cv2, pl1, cv1):\n",
        "    pl2_delta = input_delta.reshape(pl2.shape)\n",
        "    cv2_delta = self.pool2.backward(cv2, pl2_delta, self.conv2.activator)\n",
        "    pl1_delta = self.conv2.backward(cv2_delta, pl1.shape)\n",
        "    cv1_delta = self.pool1.backward(cv1, pl1_delta, self.conv1.activator)\n",
        "    return pl2_delta, cv2_delta, pl1_delta, cv1_delta\n",
        "\n",
        "  def __update_epsilon(self, epsilon, gamma):\n",
        "    return gamma * epsilon\n",
        "\n",
        "  def __set_loss(self, epochs):\n",
        "    self.__loss = np.zeros(epochs)\n",
        "\n",
        "  def __accumulate_loss(self, y, t, n_data, epo):\n",
        "    self.__loss[epo] += self.error.delta(y, t) / n_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_anuwistHs8t"
      },
      "source": [
        "## convolution.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Convolution(object):\n",
        "  def __init__(self, m, k, kh, kw, act):\n",
        "    self.kh = kh\n",
        "    self.kw = kw\n",
        "    self.weight = np.random.normal(0.0, np.sqrt(2.0 / (m * kh * kw)), (m, k, kh, kw))\n",
        "    self.activator = act\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.activator.activate(self.__forward(X))\n",
        "\n",
        "  def backward(self, delta, shape):\n",
        "    s_batch, k, h, w = delta.shape\n",
        "    delta_patch = np.tensordot(delta.reshape(s_batch, k, h * w), self.weight, (1, 0))\n",
        "    return self.__patch2im(delta_patch, h, w, shape)\n",
        "\n",
        "  def update_weight(self, delta, epsilon):\n",
        "    s_batch, k, h, w = delta.shape\n",
        "    self.weight -= epsilon * self.__grad(delta, s_batch, k, h, w)\n",
        "\n",
        "  def __forward(self, X):\n",
        "    s_batch, k, xh, xw = X.shape\n",
        "    m = self.weight.shape[0]\n",
        "    oh, ow = xh - int(self.kh / 2) * 2, xw - int(self.kw / 2) * 2\n",
        "    self.__patch = self.__im2patch(X, s_batch, k, oh, ow)\n",
        "    return np.tensordot(self.__patch, self.weight, ((2, 3, 4), (1, 2, 3))).swapaxes(1, 2).reshape(s_batch, m, oh, ow)\n",
        "\n",
        "  def __im2patch(self, X, s_batch, k, oh, ow):\n",
        "    patch = np.zeros((s_batch, oh * ow, k, self.kh, self.kw))\n",
        "    for j in range(oh):\n",
        "      for i in range(ow):\n",
        "        patch[:, j * ow + i, :, :, :] = X[:, :, j:j+self.kh, i:i+self.kw]\n",
        "    return patch\n",
        "\n",
        "  def __patch2im(self, patch, h, w, shape):\n",
        "    im = np.zeros(shape)\n",
        "    for j in range(h):\n",
        "      for i in range(w):\n",
        "        im[:, :, j:j+self.kh, i:i+self.kw] += patch[:, j * w + i]\n",
        "    return im\n",
        "\n",
        "  def __grad(self, delta, s_batch, k, h, w):\n",
        "    return np.tensordot(delta.reshape(s_batch, k, h * w), self.__patch, ((0, 2), (0, 1))) / s_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMqlKleYIJ8Y"
      },
      "source": [
        "## error.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Error:\n",
        "  class squared(object):\n",
        "    def __init__(self):\n",
        "      'squared class'\n",
        "\n",
        "    def delta(self, y, t):\n",
        "      return (y - t).T.dot(y - t).sum() / 2.0\n",
        "\n",
        "    def derivated_delta(self, y, t):\n",
        "      return y - t\n",
        "\n",
        "\n",
        "  class cross_entropy(object):\n",
        "    def __init__(self):\n",
        "      'cross entropy'\n",
        "\n",
        "    def delta(self, y, t):\n",
        "      return (-t * np.log(y)).sum()\n",
        "\n",
        "    def derivated_delta(self, y, t):\n",
        "      return (y - t) / (y * (1.0 - y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i6yHHYcIJ-S"
      },
      "source": [
        "## nn.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class NN(object):\n",
        "  def __init__(self, n_input, n_hidden, n_output, input_act, hidden_act, output_act):\n",
        "    self.n_input = n_input\n",
        "    self.n_hidden = n_hidden\n",
        "    self.n_output = n_output\n",
        "    self.hidden_weight = np.random.randn(n_hidden, n_input + 1) * 0.01\n",
        "    self.output_weight = np.random.randn(n_output, n_hidden + 1) * 0.01\n",
        "    self.input_act = input_act\n",
        "    self.hidden_act = hidden_act\n",
        "    self.output_act = output_act\n",
        "\n",
        "  def forward(self, x):\n",
        "    z = self.__forward(x, self.hidden_weight, self.hidden_act)\n",
        "    y = self.__forward(z, self.output_weight, self.output_act)\n",
        "    return z, y\n",
        "\n",
        "  def backward(self, t, y, z, u, error):\n",
        "    output_delta = y - t\n",
        "    # error.derivated_delta(t, y) * self.output_act.derivate(y)\n",
        "    hidden_delta = self.__delta(self.output_weight, output_delta, z, self.hidden_act)\n",
        "    input_delta = self.__delta(self.hidden_weight, hidden_delta, u, self.input_act)\n",
        "    return output_delta, hidden_delta, input_delta\n",
        "\n",
        "  def update_weight(self, output_delta, hidden_delta, z, u, epsilon, lam):\n",
        "    s_batch = z.shape[1]\n",
        "    reg_term = np.hstack((np.zeros((self.n_output, 1)), self.output_weight[:, 1:]))\n",
        "    self.output_weight -= epsilon * (self.__grad(z, output_delta, s_batch) + lam * reg_term)\n",
        "    self.hidden_weight -= epsilon * self.__grad(u, hidden_delta, s_batch)\n",
        "\n",
        "  def __forward(self, x, weight, act):\n",
        "    return act.activate(weight.dot(np.vstack((np.ones((x.shape[1])), x))))\n",
        "\n",
        "  def __delta(self, weight, delta, x, act):\n",
        "    return weight[:, 1:].T.dot(delta) * act.derivate(x)\n",
        "\n",
        "  def __grad(self, x, delta, s_batch):\n",
        "    return delta.dot(np.vstack((np.ones((1, x.shape[1])), x)).T) / s_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb9lR0oOIKBY"
      },
      "source": [
        "## pooling.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Pooling(object):\n",
        "  def __init__(self, kh, kw, s):\n",
        "    self.kh = kh\n",
        "    self.kw = kw\n",
        "    self.s = s\n",
        "\n",
        "  def forward(self, X):\n",
        "    s_batch, k, h, w = X.shape\n",
        "    oh, ow = int((h - self.kh) / self.s) + 1, int((w - self.kw) / self.s) + 1\n",
        "    val, self.__ind = self.__max(X, s_batch, k, oh, ow)\n",
        "    return val\n",
        "\n",
        "  def backward(self, X, delta, act):\n",
        "    s_batch, k, h, w = X.shape\n",
        "    oh, ow = delta.shape[2:]\n",
        "    rh, rw = int(h / oh), int(w / ow)\n",
        "    ind = np.arange(s_batch * k * oh * ow) * rh * rw + self.__ind.flatten()\n",
        "    return self.__backward(delta, ind, s_batch, k, h, w, oh, ow) * act.derivate(X)\n",
        "\n",
        "  def __max(self, X, s_batch, k, oh, ow):\n",
        "    patch = self.__im2patch(X, s_batch, k, oh, ow)\n",
        "    return map(lambda _f: _f(patch, axis = 3).reshape(s_batch, k, oh, ow), [np.max, np.argmax])\n",
        "\n",
        "  def __im2patch(self, X, s_batch, k, oh, ow):\n",
        "    patch = np.zeros((s_batch, oh * ow, k, self.kh, self.kw))\n",
        "    for j in range(oh):\n",
        "      for i in range(ow):\n",
        "        _j, _i = j * self.s, i * self.s\n",
        "        patch[:, j * ow + i, :, :, :] = X[:, :, _j:_j+self.kh, _i:_i+self.kw]\n",
        "    return patch.swapaxes(1, 2).reshape(s_batch, k, oh * ow, -1)\n",
        "\n",
        "  def __backward(self, delta, ind, s_batch, k, h, w, oh, ow):\n",
        "    _delta = np.zeros(s_batch * k * h * w)\n",
        "    _delta[ind] = delta.flatten()\n",
        "    return _delta.reshape(s_batch, k, oh, ow, self.kh, self.kw).swapaxes(3, 4).reshape(s_batch, k, h, w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbSa2Lp2IKEH"
      },
      "source": [
        "## main.py\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def read_data(fn):\n",
        "  ml = np.loadtxt(fn, delimiter = ',')\n",
        "  X, t = np.hsplit(ml, [-1])\n",
        "  return X / X.max(), t.astype('int')\n",
        "\n",
        "def create_label(t, n_data, n_class):\n",
        "  T = np.zeros((n_data, n_class))\n",
        "  T[np.arange(n_data), t[:, 0]] = 1.0\n",
        "  return T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPHCli_PUyP1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wb3dcUJU2Ku",
        "outputId": "ca223767-d7c9-42d5-e1ac-995db3cbada2"
      },
      "source": [
        "print('make train data...')\n",
        "fn_train = 'https://pjreddie.com/media/files/mnist_train.csv'\n",
        "X1, t1 = read_data(fn_train)\n",
        "n_data1, n_input1 = X1.shape\n",
        "n_class1 = np.unique(t1).size\n",
        "T1 = create_label(t1, n_data1, n_class1)\n",
        "\n",
        "i1 = np.random.permutation(n_data1)[:len(X1)]\n",
        "X_train = X1[i1, :].reshape(len(X1), 1, 28, 28)\n",
        "T_train = T1[i1, :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make train data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6GYaymQVqvZ",
        "outputId": "9917a8bd-4943-42b1-bbf2-2d49f038ab65"
      },
      "source": [
        "print('make test data...')\n",
        "fn_test = 'https://pjreddie.com/media/files/mnist_test.csv'\n",
        "X2, t2 = read_data(fn_test)\n",
        "n_data2, n_input2 = X2.shape\n",
        "n_class2 = np.unique(t2).size\n",
        "T2 = create_label(t2, n_data2, n_class2)\n",
        "\n",
        "i2 = np.random.permutation(n_data2)[:len(X2)]\n",
        "X_test = X2[i2, :].reshape(len(X2), 1, 28, 28)\n",
        "T_test = T2[i2, :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make test data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAvN2JFzWMXO",
        "outputId": "c1628c6c-52a9-48c7-f311-16d1e3d03830"
      },
      "source": [
        "print('initialize...')\n",
        "linear, sigmoid, softmax, relu = Activator.linear(), Activator.sigmoid(), Activator.softmax(), Activator.relu()\n",
        "conv1, conv2 = Convolution(20, 1, 5, 5, relu), Convolution(50, 20, 5, 5, relu)\n",
        "pool1, pool2 = Pooling(2, 2, 2), Pooling(2, 2, 2)\n",
        "neural = NN(800, 500, 10, linear, sigmoid, softmax)\n",
        "error = Error.cross_entropy()\n",
        "cnn = CNN(conv1, pool1, conv2, pool2, neural, error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initialize...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "kMTrL--8WJMt",
        "outputId": "a6a52e7e-97a5-43ca-d88e-d1879d66bae6"
      },
      "source": [
        "print('train...')\n",
        "cnn.train(X_train, T_train, epsilon = 0.005, lam = 0.0001, gamma = 0.9, s_batch = 5, epochs = 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:38: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2167: RuntimeWarning: invalid value encountered in ? (vectorized)\n",
            "  outputs = ufunc(*inputs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-512a9b113930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-ad878c8e754c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, T, epsilon, lam, gamma, s_batch, epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutput_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mpl2_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl1_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv1_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# update weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-ad878c8e754c>\u001b[0m in \u001b[0;36m__backward\u001b[0;34m(self, input_delta, pl2, cv2, pl1, cv1)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mcv2_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl2_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mpl1_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mcv1_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl1_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpl2_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl1_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv1_delta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-535dbca048d7>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, X, delta, act)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mrh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_batch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-def269eb5f56>\u001b[0m in \u001b[0;36mderivate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0m_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_x\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2165\u001b[0m                       for a in args]\n\u001b[1;32m   2166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2167\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-def269eb5f56>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(_x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0m_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_x\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vY9ruBTUydF"
      },
      "source": [
        "print('predict...')\n",
        "Y_test = cnn.predict(X_test)\n",
        "accuracy = cnn.accuracy(Y_test, T_test)\n",
        "print('accuracy: {0}'.format(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIbBkunYPBzX"
      },
      "source": [
        "print('save figure of loss...')\n",
        "cnn.save_lossfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPkM33vrS5KJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fLZRn2uQIM4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}